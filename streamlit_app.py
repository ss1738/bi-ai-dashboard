# AI BI Dashboard â€” Streamlit (Polished + Saved Views + Branded Reports)
# Save as: streamlit_app.py

import base64
from io import BytesIO
from dataclasses import dataclass
from datetime import datetime
from typing import List, Optional

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt

# ===== Report Branding Config =====
BRAND = {
    "product_name": "AI BI Dashboard",
    "tagline": "Insights in minutes â€” not months.",
    "company": "Your Company Ltd",
    "accent": "#5b8def",          # theme color
    "logo_path": None,            # e.g., "assets/logo.png" (optional)
    "footer_note": "Generated by AI BI Dashboard â€” Early Access 2025",
}

# ---------- UI polish ----------
st.set_page_config(page_title="AI BI Dashboard", page_icon="ðŸ“Š", layout="wide")
st.markdown(
    f"""
    <style>
      :root {{ --accent: {BRAND['accent']}; }}
      .stTabs [data-baseweb="tab-list"] {{ gap: 6px; }}
      .stTabs [data-baseweb="tab"] {{
        background: #f7f7f9; padding: 10px 12px; border-radius: 10px; border: 1px solid #eee;
      }}
      .stTabs [aria-selected="true"] {{ background: white; border-color: #ddd; }}
      .metric-card {{ background:#fff; border:1px solid #eee; padding:14px 16px; border-radius:14px; }}
      .accent {{ color: var(--accent); }}
      .btn-accent button {{ background: var(--accent) !important; color:#fff !important; }}
    </style>
    """,
    unsafe_allow_html=True,
)

# ---------- Helpers ----------

def df_to_xlsx_bytes(sheets: dict) -> bytes:
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="xlsxwriter") as writer:
        for name, d in (sheets or {}).items():
            if d is None:
                continue
            try:
                (d if isinstance(d, pd.DataFrame) else pd.DataFrame(d)).to_excel(
                    writer, index=False, sheet_name=(name or "sheet")[:31]
                )
            except Exception:
                try:
                    pd.DataFrame(d).to_excel(
                        writer, index=False, sheet_name=(name or "sheet")[:31]
                    )
                except Exception:
                    pass
    return bio.getvalue()

def make_demo_data(n_days: int = 365, seed: int = 7) -> pd.DataFrame:
    rng = np.random.default_rng(seed)
    start = pd.Timestamp.today().normalize() - pd.Timedelta(days=n_days)
    dates = pd.date_range(start, periods=n_days, freq="D")
    categories = ["Online", "Retail", "Wholesale"]
    regions = ["EMEA", "APAC", "AMER"]
    products = ["A", "B", "C", "D"]

    data: List[dict] = []
    base = 1000
    season = np.sin(np.linspace(0, 6 * np.pi, n_days)) * 150
    trend = np.linspace(0, 250, n_days)
    for i, d in enumerate(dates):
        for c in categories:
            for r in regions:
                noise = rng.normal(0, 80)
                amount = max(0, base + season[i] + trend[i] + noise + rng.normal(0, 30))
                units = max(1, int(10 + season[i]/20 + rng.normal(0, 3)))
                price = amount / units
                data.append({
                    "date": d,
                    "channel": c,
                    "region": r,
                    "product": rng.choice(products),
                    "revenue": round(amount, 2),
                    "units": units,
                    "price": round(price, 2),
                })
    return pd.DataFrame(data)

def parse_query_list(val: Optional[str]) -> Optional[List[str]]:
    if val is None: return None
    if isinstance(val, list): val = val[0]
    val = str(val).strip()
    if not val: return None
    return [v for v in val.split(",") if v]

def get_query_filters():
    qp = st.query_params
    r = parse_query_list(qp.get("region"))
    c = parse_query_list(qp.get("channel"))
    p = parse_query_list(qp.get("product"))
    return r, c, p

def set_query_filters(regions: Optional[List[str]], channels: Optional[List[str]], products: Optional[List[str]]):
    qp = dict(st.query_params)
    if regions: qp["region"] = ",".join(regions)
    else: qp.pop("region", None)
    if channels: qp["channel"] = ",".join(channels)
    else: qp.pop("channel", None)
    if products: qp["product"] = ",".join(products)
    else: qp.pop("product", None)
    st.query_params.clear()
    for k, v in qp.items():
        st.query_params[k] = v

def share_link(anchor: Optional[str] = None) -> str:
    # Returns relative link with current query params + optional anchor
    parts = []
    if "region" in st.query_params: parts.append(f"region={st.query_params['region']}")
    if "channel" in st.query_params: parts.append(f"channel={st.query_params['channel']}")
    if "product" in st.query_params: parts.append(f"product={st.query_params['product']}")
    path = "?" + "&".join(parts) if parts else ""
    if anchor: path += f"#{anchor}"
    return path

def kpi_card(label: str, value: str, helptext: str = "") -> None:
    with st.container(border=True):
        st.markdown(
            f"""
            <div class='metric-card'>
              <h4 style="margin:0 0 6px 0">{label}</h4>
              <h2 class="accent" style="margin:0 0 6px 0">{value}</h2>
              <div style="color:#666;font-size:12px;">{helptext}</div>
            </div>
            """,
            unsafe_allow_html=True,
        )

# ---------- Branded Report Builders ----------

def _b64_logo(logo_path: Optional[str]) -> Optional[str]:
    if not logo_path: return None
    try:
        with open(logo_path, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception:
        return None

def build_report_md(kpis: dict, filters_txt: str, movers_csv: Optional[str], note: Optional[str]) -> str:
    lines = [
        f"# {BRAND['product_name']}",
        f"*{BRAND['tagline']}*",
        "",
        f"**Filters:** {filters_txt}",
        "",
        "## KPIs",
        f"- Total Revenue: {kpis.get('total_revenue','â€“')}",
        f"- Units Sold: {kpis.get('units','â€“')}",
        f"- Avg Price: {kpis.get('avg_price','â€“')}",
    ]
    if movers_csv:
        lines += ["", "## Top Movers (last period vs prior)", "```csv", movers_csv.strip(), "```"]
    if note:
        lines += ["", "## Notes", note]
    lines += ["", f"*{BRAND['footer_note']}*"]
    return "\n".join(lines)

def build_report_html(
    kpis: dict,
    filters_txt: str,
    movers_df: Optional[pd.DataFrame],
    note: Optional[str],
    chart_png_b64: Optional[str] = None,
) -> bytes:
    accent = BRAND["accent"]
    logo_b64 = _b64_logo(BRAND.get("logo_path"))
    logo_html = f"<img src='data:image/png;base64,{logo_b64}' style='height:36px;margin-right:10px'/>" if logo_b64 else ""
    kpi_items = "".join(
        f"<li><b>{label}</b>: {value}</li>"
        for label, value in [
            ("Total Revenue", kpis.get("total_revenue", "â€“")),
            ("Units Sold",   kpis.get("units", "â€“")),
            ("Avg Price",    kpis.get("avg_price", "â€“")),
        ]
    )
    movers_html = movers_df.head(12).to_html(index=False) if (movers_df is not None and not movers_df.empty) else ""
    chart_html = f"<img src='data:image/png;base64,{chart_png_b64}' style='max-width:100%;border:1px solid #eee;border-radius:8px'/>" if chart_png_b64 else ""

    html = f"""<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>{BRAND['product_name']} â€” Report</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    :root {{ --accent: {accent}; }}
    * {{ box-sizing: border-box; }}
    body {{ font-family: Inter, Segoe UI, Roboto, Arial, sans-serif; color:#222; margin:0; background:#fff; }}
    .wrap {{ max-width: 980px; margin: 0 auto; padding: 24px; }}
    .card {{ background:#fff; border:1px solid #eee; border-radius:14px; padding:18px; margin:12px 0; }}
    .muted {{ color:#666; }}
    .header {{ display:flex; align-items:center; gap:12px; }}
    .title {{ margin:0; font-size:28px; }}
    .tagline {{ margin:2px 0 0; color:#555; }}
    .badge {{ background: var(--accent); color:#fff; padding:2px 8px; border-radius:999px; font-size:12px; }}
    h2 {{ margin-top: 0.2rem; }}
    table {{ border-collapse: collapse; width: 100%; }}
    th, td {{ border: 1px solid #eee; padding: 8px; text-align: left; }}
    .footer {{ margin-top: 32px; padding: 16px; color:#666; font-size:13px; border-top:1px dashed #e5e5e5; }}
    @media print {{
      .card {{ break-inside: avoid; }}
      .footer {{ position: fixed; bottom: 0; left: 0; right: 0; }}
    }}
  </style>
</head>
<body>
  <div class="wrap">
    <div class="header">
      {logo_html}
      <div>
        <h1 class="title">{BRAND['product_name']}</h1>
        <div class="tagline">{BRAND['tagline']}</div>
      </div>
      <div style="flex:1"></div>
      <span class="badge">Auto-generated</span>
    </div>

    <div class="card">
      <div class="muted">Filters</div>
      <div>{filters_txt}</div>
    </div>

    <div class="card">
      <h2>KPIs</h2>
      <ul>{kpi_items}</ul>
    </div>

    {"<div class='card'><h2>Trend</h2>"+chart_html+"</div>" if chart_html else ""}

    {("<div class='card'><h2>Top Movers (last period vs prior)</h2>"+movers_html+"</div>") if movers_html else ""}

    {("<div class='card'><h2>Notes</h2><div>"+(note or "").replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")+"</div></div>")}

    <div class="footer">
      {BRAND['footer_note']} â€¢ {BRAND['company']}
    </div>
  </div>
</body>
</html>"""
    return html.encode("utf-8")

# ---------- Sidebar: Data & Filters & Saved Views ----------

st.sidebar.title("AI BI Dashboard")

src = st.sidebar.radio("Data source", ["Use demo data", "Upload CSV/Parquet/Excel"], index=0)
if src == "Upload CSV/Parquet/Excel":
    upl = st.sidebar.file_uploader("Upload a file", type=["csv","parquet","xlsx","xls"])
    if upl is not None:
        try:
            if upl.name.lower().endswith(".csv"):
                df = pd.read_csv(upl)
            elif upl.name.lower().endswith(".parquet"):
                df = pd.read_parquet(upl)
            else:
                df = pd.read_excel(upl)
        except Exception as e:
            st.sidebar.error(f"Failed to read file: {e}")
            df = make_demo_data()
    else:
        df = make_demo_data()
else:
    df = make_demo_data()

# date parsing
if "date" in df.columns and not np.issubdtype(df["date"].dtype, np.datetime64):
    try:
        df["date"] = pd.to_datetime(df["date"])
    except Exception:
        pass

regions_all = sorted(df["region"].dropna().unique().tolist()) if "region" in df.columns else []
channels_all = sorted(df["channel"].dropna().unique().tolist()) if "channel" in df.columns else []
products_all = sorted(df["product"].dropna().unique().tolist()) if "product" in df.columns else []

q_regions, q_channels, q_products = get_query_filters()
with st.sidebar.expander("Filters", expanded=True):
    sel_regions = st.multiselect("Region", regions_all, default=(q_regions or regions_all))
    sel_channels = st.multiselect("Channel", channels_all, default=(q_channels or channels_all))
    sel_products = st.multiselect("Product", products_all, default=(q_products or products_all))
    if st.button("Apply filters", type="primary"):
        set_query_filters(sel_regions, sel_channels, sel_products)
        st.rerun()

# Saved views
if "saved_views" not in st.session_state:
    st.session_state.saved_views = {}
with st.sidebar.expander("Saved Views", expanded=False):
    name_new = st.text_input("Name this view")
    col_sv1, col_sv2 = st.columns([1,1])
    if col_sv1.button("Save current"):
        st.session_state.saved_views[name_new or f"View {len(st.session_state.saved_views)+1}"] = {
            "regions": sel_regions,
            "channels": sel_channels,
            "products": sel_products,
        }
        st.success("Saved.")
    if col_sv2.button("Clear all"):
        st.session_state.saved_views = {}
    if st.session_state.saved_views:
        st.markdown("**Your views**")
        for nm, params in st.session_state.saved_views.items():
            c1, c2, c3 = st.columns([1,1,2])
            if c1.button(f"Apply: {nm}", key=f"apply_{nm}"):
                set_query_filters(params.get("regions"), params.get("channels"), params.get("products"))
                st.rerun()
            link = "?" + "&".join(
                f"{k}={','.join(v)}" for k, v in [
                    ("region", params.get("regions") or []),
                    ("channel", params.get("channels") or []),
                    ("product", params.get("products") or []),
                ] if v
            )
            c2.write(f"[Share link]({link or '?'})")
            if c3.button(f"Delete {nm}", key=f"del_{nm}"):
                st.session_state.saved_views.pop(nm, None)
                st.rerun()

# Apply filters to df
if sel_regions: df = df[df["region"].isin(sel_regions)]
if sel_channels: df = df[df["channel"].isin(sel_channels)]
if sel_products: df = df[df["product"].isin(sel_products)]

num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]

# ---------- Tabs ----------
TABS = st.tabs([
    "ðŸ“Š Dashboard",
    "ðŸ§© Segmentation",
    "ðŸš¨ Anomalies",
    "ðŸ“ˆ Forecast",
    "ðŸ§  AI Insights",
    "ðŸ•’ Early Access Waitlist",
])

# ---------- TAB 1: Dashboard ----------
with TABS[0]:
    st.markdown("### Overview")

    # KPIs
    c1, c2, c3, c4 = st.columns(4)
    total_rev = float(df.get("revenue", pd.Series(dtype=float)).sum()) if "revenue" in df.columns else float(df.select_dtypes(include=np.number).sum().sum())
    total_units = int(df.get("units", pd.Series(dtype=float)).sum()) if "units" in df.columns else len(df)
    avg_price = (df["revenue"].sum() / max(1, df["units"].sum())) if {"revenue","units"}.issubset(df.columns) else np.nan
    c1.metric("Total Revenue", f"Â£{total_rev:,.0f}")
    c2.metric("Units Sold", f"{total_units:,}")
    c3.metric("Avg Price", f"Â£{avg_price:,.2f}" if not np.isnan(avg_price) else "â€“")
    c4.metric("Rows", f"{len(df):,}")

    # Trend chart
    if {"date","revenue"}.issubset(df.columns):
        daily = df.groupby(pd.to_datetime(df["date"]).dt.to_period("D").dt.start_time)["revenue"].sum().reset_index()
        st.altair_chart(
            alt.Chart(daily).mark_line().encode(
                x="date:T", y=alt.Y("revenue:Q", title="Revenue"),
                tooltip=["date:T", alt.Tooltip("revenue:Q", format=",.0f")]
            ).properties(height=320),
            use_container_width=True,
        )

    # Download center (deep-link anchor)
    st.markdown("<div id='download-data'></div>", unsafe_allow_html=True)
    st.subheader("Download Data")
    st.caption("Exports the CURRENTLY FILTERED dataset shown above.")
    st.download_button("Download CSV", df.to_csv(index=False).encode("utf-8"), file_name="data_filtered.csv")
    st.download_button("Download JSON", df.to_json(orient="records").encode("utf-8"), file_name="data_filtered.json")
    xlsx_bytes = df_to_xlsx_bytes({
        "data_filtered": df,
        "anomalies": st.session_state.get("__last_anomalies_df", pd.DataFrame()),
        "forecast": st.session_state.get("__last_forecast_df", pd.DataFrame()),
    })
    st.download_button("Download XLSX", xlsx_bytes, file_name="export.xlsx")

    # Copy deep link button
    st.button("ðŸ”— Copy link to this section", key="copy_dl_btn")
    st.components.v1.html(
        """
        <script>
        (function(){
          function bind(){
            const btn = Array.from(window.parent.document.querySelectorAll('button')).find(b => /Copy link to this section/.test(b.textContent));
            if(!btn || btn.__bound){ setTimeout(bind, 600); return; }
            btn.__bound = true;
            btn.addEventListener('click', () => {
              try{
                const url = window.location.origin + window.location.pathname + window.location.search + '#download-data';
                navigator.clipboard.writeText(url);
              }catch(e){}
            });
          }
          setTimeout(bind, 400);
          // smooth scroll on #download-data
          setTimeout(() => {
            try { if (window.location.hash === "#download-data") {
              const el = document.getElementById("download-data");
              if (el) el.scrollIntoView({behavior: "smooth", block: "start"}); }
            } catch (e) {}
          }, 500);
        })();
        </script>
        """,
        height=0,
    )

    # -------- Branded Report Generator --------
    st.markdown("---")
    with st.expander("ðŸ“„ Generate Report (Markdown / HTML)", expanded=False):
        include_chart = st.checkbox("Include trend chart (best-effort)", value=True)
        include_movers = st.checkbox("Include Top Movers (by region)", value=True)
        note = st.text_area("Add a note (optional)", placeholder="Context, decisions, risksâ€¦")

        filters_txt = (
            f"Region: {', '.join(sel_regions) if sel_regions else 'All'}; "
            f"Channel: {', '.join(sel_channels) if sel_channels else 'All'}; "
            f"Product: {', '.join(sel_products) if sel_products else 'All'}"
        )

        kpis = {
            "total_revenue": f"Â£{total_rev:,.0f}",
            "units": f"{total_units:,}",
            "avg_price": f"Â£{avg_price:,.2f}" if not np.isnan(avg_price) else "â€“",
        }

        movers_df = None
        movers_csv = None
        if include_movers and {"date","revenue","region"}.issubset(df.columns):
            g = (df.assign(_p=pd.to_datetime(df["date"]).dt.to_period("M").dt.start_time)
                   .groupby(["region","_p"])["revenue"].sum().reset_index().sort_values("_p"))
            g["prev"] = g.groupby("region")["revenue"].shift(1)
            g["pct_change"] = (g["revenue"] - g["prev"]) / g["prev"] * 100
            lastp = g["_p"].max()
            movers_df = g[g["_p"] == lastp].dropna(subset=["pct_change"]).sort_values("pct_change", ascending=False)
            movers_df = movers_df.rename(columns={"_p":"period","revenue":"value"})[["region","value","pct_change"]].copy()
            movers_df["value"] = movers_df["value"].map(lambda x: round(x,2))
            movers_df["pct_change"] = movers_df["pct_change"].map(lambda x: round(x,2))
            movers_csv = movers_df.to_csv(index=False)

        chart_b64 = None
        if include_chart and {"date","revenue"}.issubset(df.columns):
            try:
                daily = df.groupby(pd.to_datetime(df["date"]).dt.to_period("D").dt.start_time)["revenue"].sum().reset_index()
                chart = alt.Chart(daily).mark_line().encode(x="date:T", y="revenue:Q")
                from altair_saver import save as alt_save  # optional
                png_io = BytesIO()
                alt_save(chart, png_io, format="png", method="vl-convert")
                chart_b64 = base64.b64encode(png_io.getvalue()).decode()
            except Exception:
                chart_b64 = None  # still build report

        md_bytes = build_report_md(kpis, filters_txt, movers_csv, note).encode("utf-8")
        html_bytes = build_report_html(kpis, filters_txt, movers_df, note, chart_png_b64=chart_b64)

        colr1, colr2 = st.columns(2)
        colr1.download_button("Download Markdown (.md)", md_bytes, file_name="ai_bi_report.md")
        colr2.download_button("Download HTML (.html)", html_bytes, file_name="ai_bi_report.html")

# ---------- TAB 2: Segmentation (placeholder to keep code light) ----------
with TABS[1]:
    st.markdown("### ðŸ§© Segmentation")
    st.info("KMeans clustering with profiles can be added here. (Keeping lightweight to focus on reports & saved views.)")

# ---------- TAB 3: Anomalies (stub for XLSX sheet) ----------
with TABS[2]:
    st.markdown("### ðŸš¨ Anomalies")
    st.caption("Stub anomalies saved so XLSX export includes a sheet.")
    st.session_state["__last_anomalies_df"] = df.head(100).copy()
    st.dataframe(st.session_state["__last_anomalies_df"], use_container_width=True)

# ---------- TAB 4: Forecast (simple preview + sheet for XLSX) ----------
with TABS[3]:
    st.markdown("### ðŸ“ˆ Forecast")
    if {"date","revenue"}.issubset(df.columns):
        daily = df.groupby(pd.to_datetime(df["date"]).dt.to_period("D").dt.start_time)["revenue"].sum().reset_index()
        last = daily["date"].max()
        fut = pd.date_range(last + pd.Timedelta(days=1), periods=14, freq="D")
        fdf = pd.DataFrame({"date": fut, "forecast": np.linspace(daily["revenue"].iloc[-1], daily["revenue"].iloc[-1]*1.05, len(fut))})
        st.line_chart(fdf.set_index("date"))
        st.session_state["__last_forecast_df"] = fdf.copy()
    else:
        st.warning("Need date & revenue columns for forecast preview.")

# ---------- TAB 5: AI Insights (placeholder) ----------
with TABS[4]:
    st.markdown("### ðŸ§  AI Insights")
    st.info("Heuristic cards & movers plug in here â€” focus of this build is Branded Reports + Saved Views + Exports.")

# ---------- TAB 6: Waitlist ----------
with TABS[5]:
    st.markdown("### ðŸ•’ Early Access Waitlist")
    st.caption("Embed your Google Form or capture locally.")
    # If you have an embed URL in secrets, use that; else show a demo placeholder
    form_url = st.secrets.get("WAITLIST", {}).get("google_form_iframe_url", "")
    if form_url:
        st.components.v1.iframe(form_url, height=700, scrolling=True)
    else:
        st.components.v1.iframe("https://docs.google.com/forms/d/e/1FAIpQLSf-demo-form/viewform?embedded=true", height=650)

# Footer
st.markdown("---")
st.caption("AI BI Dashboard â€¢ Saved Views â€¢ Branded Reports â€¢ Deep links â€¢ CSV/JSON/XLSX exports")
